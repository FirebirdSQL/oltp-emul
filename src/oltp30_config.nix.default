####################################################################
# OLTP-EMUL test for Firebird database - configuration parameters.
# To get last version type following command:
# git clone https://github.com/FirebirdSQL/oltp-emul .
# This file is used for launching test and ISQL sessions on POSIX host
# with running Firebird 2.5.
# Parameters are extracted by '1run_oltp_emul.sh' command scenario.
####################################################################

#::::::::::::::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR START AND FINISH ISQL SESSIONS
#::::::::::::::::::::::::::::::::::::::::::::::::

    # Folder with Firebird console utilities (isql, fbsvcmgr).
    # Trailing backslash is optional.
    # Allows referencing to existing OS environment variable by using dollar sign.
    # Samples:
    # fbc = $FB30_HOME/bin
    # fbc = /opt/firebird.30/bin

    fbc  = /opt/firebird/bin

    # Alias or full path and file name of database.
    # If you want this database be created by test itself, specify it as
    # FULL PATH and file name. Use only ASCII characters in its name.
    # Allows referencing to existing OS environment variable by using dollar sign.
    # Use forward slash (/) in all cases, even when database is on Windows host.
    # Samples:
    # dbnm = $HOME/data/oltp30.fdb
    # dbnm = /var/db/fb30/oltp30.fdb
    # dbnm = c:/mix/firebird/oltptest/oltp30.fdb

    dbnm = /home/bases/oltp30.fdb


    # Parameters for remote connection and authentication.
    # Will be ignored by command scenario if FB runs in embedded mode.

    host = localhost
    port = 3333
    usr =  SYSDBA
    pwd =  masterkey


    # Folder for storing .sql scenarios, STDOUT and STDERR logs of every working isql session.
    # Trailing backslash is optional.
    # Allows referencing to existing OS environment variable by using dollar sign.
    # Samples:
    # tmpdir = /var/tmp/logs.oltp30
    # tmpdir = $TMP/logs.oltp30

    tmpdir = /var/tmp/logs.oltp30


    # Condition for removing or preserving isql logs after test finish.
    # Possible values: always | never | if_no_severe_errors
    # Option 'always' means that ISQL logs in $tmpdir will be removed after test finish regardless any result.
    # Option 'never' means that ISQL logs will be always preserved.
    # Option 'if_no_severe_errors' means that ISQL logs will be removed only if no severe exceptions occured.
    # Test considers following exceptions as 'severe':
    #   335544558 check_constraint     (Operation violates CHECK constraint @1 on view or table @2).
    #   335544347 not_valid            (Validation error for column @1, value "@2").
    #   335544665 unique_key_violation (Violation of PRIMARY or UNIQUE KEY constraint "..." on table ...") - if table has unique CONSTRAINT
    #   335544349 no_dup               (attempt to store duplicate value (visible to active transactions) in unique index "***") - if table has only unique INDEX

    # Recommended value: if_no_severe_errors

    remove_isql_logs = if_no_severe_errors


#:::::::::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR REPLICATION, WORKLOAD LEVEL AND PAUSES
#:::::::::::::::::::::::::::::::::::::::::::

    # Test has several settings that define how much work should be done by each business action in average.
    # All of them are considered as separate enumerations: when new ISQL session creates connection, it reads
    # "entry" setting about selected workload level and then read all other settings for THIS workload level.
    # Parameter 'working_mode' is mnemonic these enumerations. Possible values for this parameter are:
    # SMALL_01, SMALL_02, SMALL_03, MEDIUM_01, MEDIUM_02, MEDIUM_03, LARGE_01, LARGE_02, LARGE_03 and HEAVY_01
    # In case of launching from several machines ensure that all of them have the same value for this parameter.
    # Completely new workload mode can be added to the test by editing file "oltp_main_filling.sql", see there
    # sub-section "Definitions for workload modes".
    # WARNING: exception will raise on test startup if this value was mistyped and has no correspond data in DB.
    # Mnemonic name of workload mode (must be specified without quotes, case-insensitive):

    working_mode = small_03


    # MINIMAL pause duration between each business operations, in seconds.
    # This parameter has default value 0 and can be commented.
    # Pause duration will be evaluated as random value between $sleep_min and $sleep_max values.

    sleep_min=5


    # MAXIMAL pause duration between each business operations, in seconds.
    # Default: 0 - no pauses, next transaction will start immediatelly after previous commit.
    # This will lead to maximal (non-realistic) level of workload but performance score will not be affected by uknown factor
    # related to delays in all running isql sessions.
    # Delay statement will be inserted in .sql script by 1run_oltp_emul.sh; the form of this statement depends on value of
    # parameter 'sleep_ddl': if it is commented (undefined) then OS command call will be used: 'shell sleep NNN;'
    # Otherwise UDF will be invoked from separate execute block. Name of this UDF must be declared in the SQL-script defined 
    # by 'sleep_ddl' parameter.
    # NOTE. THIS PARAMETER IS MANDATORY AND CAN NOT BE COMMENTED.  SPECIFY 0 IF NO PAUSES REQUIRED.

    sleep_max=20


    # Name of .sql script with declaration of UDF that will be used for SLEEPING if sleep_max greater than 0.
    # Script must correctly drop old existent UDF with any name that contains phrases: DELAY, SLEEP or PAUSE.
    # After dropping, script also must create new UDF and test it (for checking results in log).
    # This script will be applied only when parameter 'sleep_max' greater than 0.
    # Note. The whole following phrase:
    #     declare external function <name>
    # -- must be written on the SINGLE LINE in this script (<name> will be parsed from this line as the 4th word)
    # This UDF implementation (.so file) must be stored in the server-side folder, usually /opt/firebird/UDF, which
    # is allowed to be used for UDF calls. See description for parameter 'UDFaccess' in standard firebird.conf for details.
    # Test is provided with its own UDF and appropriate declaration script named "oltp_sleepUDF_nix.sql".
    # Unpack file SleepUDF.so.bz2 and put file SleepUDF.so in any folder that is allowed by 'UDFaccess' parameter from firebird.conf.
    # NOTE. This parameter will be ignored when value of 'sleep_max' is zero.
    # Also, you can comment this parameter for using only external command ('shell sleep NNN;') when 'sleep_max' greater than 0.

    sleep_ddl=./oltp_sleepUDF_nix.sql


    # Should SET TRANSACTION statement include NO AUTO UNDO clause (1=yes, 0=no) ?
    # Value 1 is useful when most of started transactions finished successfully.
    # Especially this can be so when setting 'separate_workers' has value 1.
    # Results of benchmark (2015):
    # SuperServer:  +  5-6%
    # SuperClassic: + 10-11%
    # Recommended value: 1

    no_auto_undo = 1


    # Minimal interval in minutes between two subsequent calls of service procedure 'srv_recalc_idx_stat' which updates index statistics
    # and can take too long time (more than 3-4 minutes per table on database with size ~100Gb).
    # See SP 'srv_random_unit_choice' for choising algorithm:

    recalc_idx_min_interval = 30


    # If you plan this database work in replication process, one need to add PK constraints 
    # to all persistent tables that can be changed during test work.
    # Assign value of following parameter to 1 in order all necessary changes be added to tables DDL
    # (primary keys and triggers for some of tables).
    # Setting value to 0 will DROP all changes that are unneeded when test runs without replication.
    # This parameter can be changed 'on the fly': database recreation is NOT required, but in case
    # when database has valuable size, changes will be applied not instantly.
    
    used_in_replication = 0


#:::::::::::::::::::::::::::::::::::
# SETTINGS RELATED TO LOCK CONFLICTS
#:::::::::::::::::::::::::::::::::::

    # Do we force every ISQL session to make its job only within 'sandbox' so that no update coinflicts will occur ?
    # If yes then assign to separate_workers value 1, other wise set it to 0. 
    # NOTE. Value 0 can lead to lot of update conflicts because every ISQL can take lock to any document.

    separate_workers = 1

    # How many ISQL sessions we expect to be launched on server.
    # It is strongly recommended to choose such value of this parameter that will be close to number of actual launched ISQL sessions.

    # Recommened value: at least 100
    expected_workers = 100

    # How many documents from other's sandbox can be taken in processing by 'this' ISQL session, percent.
    # Value 0 means that we do not allow ISQL session to take any documents except those which was created by itself.
    # Value 100 means that we require for each ISQL session take for processing only OTHER's documents. 
    # Moreover, this also mean that we want ISQL session 'forget' about documents which were created by itself.
    # This will lead to extremely high number of lock-conflicts and very poor performance.
    # Recommened value: 0 - for benchmark purposes; 30...50 - for investigations.

    update_conflict_percent = 0

    # How business operations should be selected: randomly or in predictable manner.
    # Allowed values:
    # random - on occasional basis, but with respect to priority/probability of business operatrions nature;
    # predictable - forcely make every ISQL session to work using given sequence of business operations, i.e.
    #     create client order -> create order to supplier -> get invoice from supplier -> ...
    # Value 'predictable' was not deeply tested and currently can lead to poor performance.
    # Recommened value: random

    unit_selection_method = random


#::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR ADDITIONAL LOGGING 
#::::::::::::::::::::::::::::::::::::


    # Add in ISQL logs detailed info for each iteration (select from perf_log...) ?
    # Recommended value: 0
    # Note: value = 1 significantly increases disk I/O on client machine.
    # Do not use it if you are not interested on data of table 'perf_log'.

    detailed_info = 0

    # Do we add query to mon$ tables before and after each application unit 
    # in generated sql scenario (1=yes, 0=no) ? 
    # NOTE. More detailed analysis with detalization down to separate stored procedures
    # can be achieved by updating setting TRACED_UNITS in the script oltp_main_filling.sql.

    mon_unit_perf = 0


    # List of top-level units (see 'business_ops' table) which performance statistics we want 
    # to be logged by querying  mon$ tables. Logging is done by SP srv_log_mon_for_traced_units.
    # This setting is ignored if config parameter 'enable_mon_query' is 0.
    # Value can be single unit name or LIST of unit names delimited by forward slash.
    # Sample:
    #     sp_make_qty_storno/sp_kill_qty_storno/sp_multiply_rows_for_qdistr/sp_multiply_rows_for_pdistr
    # Default value: two slashes without any characters between them, i.e. no interested units for logging.

    mon_unit_list = //


    # Mnemonics of exceptions which forces test to be stopped (see calls of fn_halt_sign(gdscode)):
    # 'CK' -- halt if CHECK violation or 'not_valid' occurs (mostly this can be due to negative stock remainders)
    # 'PK' -- halt if PK or UK violation occurs
    # 'FK' -- halt if FK violation occurs // now n/a because test does not use foreign keys.
    # 'ST' -- halt if exc #335544842 appeared at the top of stack and logged into perf_log (strange problem only in 3.0 SC)
    # These mnemonics can be combined in list, i.e.: 'CK/PK/FK' - halt if CHECK or PK or FK violation occurs
    # Default: '/CK/' ==> force test to be stopped on attempt to write NEGATIVE values for stock remainders.
    # 12.02.2015: PK and FK violations *can* be detected only in sp_make_qty_storno & sp_kill_qty_storno,
    # but it is due to UNDEFINED order of UNDO when some Tx must perform bulk of such work.
    # Detailed investigation:
    # sql.ru/forum/1142271/posledstviya-nepredskazuemo-neposledovatelnyh-otkatov-izmeneniy-pri-exception
    # (EXPLANATION by dimitr see in e-mail, letters date = 12.02.2015)

    halt_test_on_errors = /CK/
     

    # How stock remainders should be verified BEFORE totalling will occur in sp_make_invnt_saldo
    # (declarative CHECK constraint on qty_xxx >= 0  should NOT ever be fired in this test!):
    # bit#0 := 1 ==> perform calls of SRV_FIND_QD_QS_MISM in doc_list_aiud in order
    #                to register mismatches between doc_data.qty and total number
    #                of rows in qdistr + qstorned for doc_data.id
    # bit#1 := 1 ==> perform calls of SRV_CHECK_NEG_REMAINDERS from doc_list_aiud
    #                (instead of totalling turnovers to `invnt_saldo` table)
    # bit#2 := 1 ==> allow dump dirty data into debug tables for analysis, see sp zdump4dbg, in case
    #                when PK/FK or check constraint is violated (see parameter 'halt_test_on_errors')
    #                NOTE: when bit#2 has value 1 then parameter 'create_with_debug_objects' must be 1
    #                to force build scenario create auxiliary Z-tables in the test DB.

    qmism_verify_bitset = 1


    # Should 1st of being launched ISQL instances also start asynchronously FBSVCMGR with 
    # opening TRACE session (1=yes; 0=no; trace session will be stopped on every end of .sql) ?
    # If yes, final report will have result of parsing trace log for that ISQL activity with
    # aggregate data about each business action and average values of:
    # 1) speed of fetches and marks per second;
    # 2) ratios reads / fetches and writes / marks.
    # These values will be divided on 10 equal time intervals in order to see changes 
    # in performance that could occur during 'test_time' phase of test.
    # There is no performance penalty when single trace session is active so one may safely
    # to set this value to 1. Note though that if you will interrupt test by brute kill all
    # ISQL sessions than you have also to kill process of FBSVCMGR which can remain active.
    # Currently implemented only for Windows!

    #trc_unit_perf = 1


#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR TEST DURATION AND PREMATURE WORK CANCELLATION
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    # Time (in minutes) to warm-up database after initial data population
    # will finish and before all following operations will be measured:
    # Recommended value: at least 30 for Firebird 2.5

    warm_time = 30

    # Limit (in minutes) to measure operations before test autostop itself:
    # Recommended value: at least 120

    test_time = 180


    # Parameter 'use_external_to_stop' defines name of text file that can be used for premature stop all working isql sessions.
    # This parameter is NOT required, i.e. it can be commented. In this case test can be stopped by running temporary script
    # '$tmpdir/1stoptest.tmp.sh' which is created every time at test start phase by script '1run_oltp_emul.sh'.
    # Usage of this script is OK for most cases except extremely high workload when establishing of new connect will be unavaliable.
    #
    # When extremely high workload is used then following message can appear on every attempt to establish new attachment:
    #     Statement failed, SQLSTATE = 08004
    #     connection rejected by remote interface
    # This message will raise both in isql which tries to connect to any database or when you try to get server version byt invoking
    # fbsvcmgr host/port:service_mgr info_server_version -- i.e. when you try to connect to server security database.
    #
    # In such case it can be more reliable to use EXTERNAL TABLE (i.e. TEXT FILE) to make all attachments to stop their work. 
    # This is so because every isql performs code that 'looks' from time to time into this external table and checks existense of at 
    # least one record in it. So, test will be quickly self-stopped when at least one non-empty line exists there. 
    # Please note that you have to make this file EMPTY before every new test run.
    #
    # If you have decided to use EXTERNAL FILE following steps must be done for premature terminate all test activity:
    #   1. Open that file in text editor and type one ascii-character there;
    #   2. Press ENTER and save this file.
    #   3. Make this file empty again when all isql sessions terminated their work.
    # Also, please note on value of parameter "ExternalFileAccess" in firebird.conf:
    #   1. When ExternalFileAccess = FULL then 'use_external_to_stop' must be full path and name of text file that will be 
    #      queried by every attachment as 'stop flag'.
    #   2. When ExternalFileAccess = RESTRICTED then 'use_external_to_stop' must be only NAME of file, without path.
    # Default setting: UNDEFINED, i.e. temporary batch '1stoptest.tmp.sh' in $tmpdir folder can be used for this.

    # use_external_to_stop = stoptext.txt


#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR DATABASE CREATION PROCESS AND INITIAL DATA FILLING 
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

    # *** NOTE *** 
    # These settings are ignored when DB already exist and has required number of documents.

    # Following two settings actual only when database does not exist 
    # and should be created by test script itself.
    # Valid options for create_with_fw are sync | async
    # Value of create_with_sweep should be not less than zero.

    create_with_fw = sync

    create_with_sweep = 20000


    # Should script be paused if database does not exist or its creation
    # did not finished properly (e.g. was interrupted; 1=yes; 0=no) ?
    # You have to set this parameter to 0 if this batch is launched by 
    # scheduler on regular basis. Otherwise it is recommended to set 1.

    wait_if_not_exists = 0

    # Should script be PAUSED after creation database objects before starting
    # initial filling with <init_docs> documents (mostly need only for debug; 1=yes, 0=no) ?
    # NOTE: test database will be (re-)created only when it does not contain all necessary objects.
    # Command scenario verifies this by searching special record in table 'SEMAPHORES' which should
    # be added there at the end-point of building process. If this record is found, test will use 
    # existing database and following parameters will be IGNORED.

    wait_after_create = 1

    # Number of documents, total of all types, for initial data population.
    # Command scenario will compare number of existing document with this
    # and create new ones only if <init_docs> still greater than obtained.
    # Recommended value: 
    # 1. For benchmark purposes - at least 30000.
    # 2. For regular running on scheduled basis - at least 10000.

    init_docs = 30000

    # Number of pages for usage during init data population ("-c" switch for ISQL).
    # Actual only for CS and SC, will be ignored in SS. Used ONLY during phase of
    # initial data population and is IGNORED on main phase of test.
    # Make sure that it is LESS than FileSystemCacheThreshold, which default is 65536.

    init_buff = 32768


    # Should command scenario - 1run_oltp_emul.sh - be PAUSED after finish creating
    # required initial number of documents (see parameter 'init_docs'; 1=yes, 0=no) ?
    # Value = 1 can be set if you want to make copy of .fdb and restore later
    # this database to 'origin' state. This can save time because of avoiding need
    # to create <init_docs> again:

    wait_for_copy = 1


    # Do we want to create some DEBUG objects (tables, views and procedures)
    # in order to:
    # 1) make dumps of all data from tables when critical error occurs;
    # 2) make miscelaneous diagnostic queries via "Z_" views.
    # Value=1 will cause "oltp_misc_debug.sql" be called when build database.
    # NB: setting 'QMISM_VERIFY_BITSET' must have bit #2 = 1 when this value = 1.
    # (see oltp_main_filling.sql)
    # Recommended value: 1

    create_with_debug_objects = 1


    # Test has two tables which are subject of very intensive modifications: QDistr and QStorned.
    # Performance highly depends on time which engine spends on handling DP, PP and index pages
    # of this tables - they are "bottlenecks" of schema. Database can be created either with two
    # these tables or with several "clones" of them (with the same stucture). The latter allows
    # to "split" workload on different areas and reduce low-level lock contention.
    # Should heavy-loaded tables (QDistr and QStorned) be splitted on several different tables,
    # each one for separate pair of operations that are 'source' and 'target' of storning ?
    # Avaliable values: 
    # 0 = do NOT split workload on several tables (instead of single QDistr and QStorned);
    # 1 = USE several tables with the same structure in order to split heavy workload on them.
    # Recommended value: nope (choose yourself and compare).

    create_with_split_heavy_tabs = 1

    # Whether heavy-loaded table (QDistr or its XQD_* clones) should have only one ("wide")
    # compound index or two separate indices (1=yes, 0=no).
    # Number of columns in compound index depends on value of two parameters:
    # 1) create_with_split_heavy_tabs and 2) create_with_separate_qdistr_idx (this).
    # Order of columns is defined by parameter 'create_with_compound_idx_selectivity'.
    # Recommended value: nope (choose yourself and compare).

    create_with_separate_qdistr_idx = 0

    # Parameter 'create_with_compound_columns_order' defines order of fields in the starting part
    # of compound index key for the table which is subject to most heavy workload - QDistr. 
    # Avaliable options: 'most_selective_first' or 'least_selective_first'.
    # When choice = 'most_selective_first' then first column of this index will have selectivity = 1 / <W>,
    # where <W> = number of rows in the table 'WARES', depends on selected workload mode.
    # Second and third columns will have poor selectivity = 1/6.
    # When choice = 'least_selective_first' then first and second columns will have poor selectivity = 1/6,
    # and third column will have selectivity = 1 / <W>.
    #
    # Actual only when create_with_split_heavy_tabs = 0.
    # Recommended value: nope (choose yourself and compare).

    create_with_compound_columns_order = most_selective_first


#:::::::::::::::::::::::::::::::::::::::::::::::::::::
#  SETTINGS FOR SCHEDULED-BASIS JOB AND TEST REPORT
#:::::::::::::::::::::::::::::::::::::::::::::::::::::

    # Total number of downloaded snapshots for storing in the folder !tmpdir!\snapshots_archive.
    # Batch scenario will keep in this folder only newest snapshots and remove old ones.
    # This setting is useful for regression investigations: you will not need to rebuild FB from sources,
    # just replace last tested FB snapshot with some of old ones. 
    # If this parameter is undefined or has value of ZERO then snapshots will NOT be stored on disk.
    # Currently implemented only for Windows!

    # max_snapshots_to_store=0

    # Do we want to replace existent Firebird instance every time before test will be launched
    # (by downloading binary archieve from official site, decompress it and stop/restart FB daemon).
    # Currently implemented only for Windows!

    # replace_instance = 0


    # Create report in HTML format (beside plain text one; 1=yes, 0=no) ?
    # Windows only. Not implemented for Linux, will be ignored at runtime.

    make_html=0

    # Do we want to include into final report result of gathering database statistics (1=yes; 0=no) ?
    # This operation can take lot of time on big databases. Replace this setting with 0 for skip it.

    run_db_statistics = 0

    # Do we want to include into final report result of database validation (1=yes; 0=no) ?
    # This operation can take lot of time on big databases. Replace this setting with 0 for skip it.

    run_db_validation = 0

    # Should final report be saved in file with name which contain info about FB, database, test settings ?
    # If no, leave this parameter commented. In that case final report will be always saved with the same name.
    # If yes, choose format of this name:
    # regular   - appropriate for quick found performance degradation, without details of test settings
    # benchmark - appropriate for analysis when different settings are applied
    # Sample of report name when this parameter = 'regular':
    # 20151102_1448_score_06543_build_31236_ss30__3h00m_100_att_fw__on.txt
    # Sample of report name when this parameter = 'benchmark':
    # ss30_fw_off_split_most__sel_1st_one_index_score_06543_build_31236__3h00m_100_att_20151102_1448.txt

    # Available options: regular | benchmark, or leave commented (undefined).

    file_name_with_test_params = regular

    # Suffix for adding at the end of report name.
    # CHANGE this value to some useful info about host location, 
    # hardware specifics, FB instance etc.

    file_name_this_host_info = nix


    # When setting 'postie_send_args' is defined batch will send final report to required e-mail using console
    # client POSTIE.EXE with arguments that are defined here plus add auto generated subject and
    # attach report. This setting is OPTIONAL. Note: executable 'postie.exe' must be either in one
    #  of PATH-list or in ..\util related to current ('src') folder. Windows only.
    # Windows only. Not implemented for Linux, will be ignored at runtime.

    #postie_send_args = -esmtp -host:mail.local -from:malert@company.com -to:foo@bar.com -user:malert@company.com -pass:QwerTyuI0p

    # Windows only. Should final report be uploaded (1=yes; 0 or undefined = no) ?
    # If no, leave this parameter commented. In that case final report will be preserved on local drive, in the folder %tmpdir%.
    # If yes, set its value to 1 and make ensure that batch ..\util\upload.bat has command that is able to upload text html content
    # to external source and store its result in text log with marking successful finish with phrase containing word 'success'.
    # One of such console utility can be found here: http://curl.haxx.se/download.html
    # Sample of its usage: curl.exe -F "name=%1" -F "file=@%2" http://some_external_site_as_storage

    #upload_report = 0


#::::::::::::::::::::::::::::::::::::::::::::
#  EXOTIC SETTINGS (USAGE WAS NOT CHECKED)
#::::::::::::::::::::::::::::::::::::::::::::

    # Do we use mtee.exe utility to provide timestamps for error messages 
    # before they are logged in .err files (1=yes, 0=no) ?
    # Windows only. Not implemented for Linux, will be ignored at runtime.

    use_mtee = 0

    # Does Firebird running in embedded mode ? (1=yes, 0=no)

    is_embed = 0

