# intro00
# intro01
#     fbc
#     clu
#     dbnm
#     host
#     port
#     usr
#     pwd
#     tmpdir
#     remove_isql_logs
# intro02
#     used_in_replication
#     working_mode
#     actions_todo_before_reconnect
#     max_cps
#     sleep_min
#     sleep_max
#     sleep_ddl
#     no_auto_undo
#     recalc_idx_min_interval
#     use_es
# intro03
#     separate_workers
#     update_conflict_percent
#     unit_selection_method
# intro04
#     detailed_info
#     use_mtee
#     mon_unit_perf
#     mon_query_role
#     mon_usr_prefix
#     mon_usr_passwd
#     mon_unit_list
#     mon_query_interval
#     trc_unit_perf
# intro05
#     halt_test_on_errors
#     qmism_verify_bitset
#     use_external_to_stop
# intro06
#     create_with_fw
#     create_with_sweep
#     wait_if_not_exists
#     wait_after_create
#     init_docs
#     expected_workers
#     init_buff
#     wait_for_copy
#     create_with_debug_objects
#     create_with_split_heavy_tabs
#     create_with_separate_qdistr_idx
#     create_with_compound_columns_order
# intro07
#     warm_time
#     test_time
#     test_intervals
#     results_storage_fbk
#     report_compressor
#     report_compress_cmd
#     etalon_dbnm
#     make_htm
#     run_db_statistics
#     run_db_validation
#     file_name_with_test_params
#     file_name_this_host_info
#     gather_hardware_info
# intro08
#     is_embed

intro00_all: ####################################################################
intro00_all: # OLTP-EMUL test for Firebird database. Configuration parameters.
intro00_all: # To get the actual version of test, enter command:
intro00_all: # 
intro00_win: # git clone --config core.autocrlf=true https://github.com/FirebirdSQL/oltp-emul .
intro00_nix: # git clone --config core.autocrlf=false https://github.com/FirebirdSQL/oltp-emul .
intro00_all: # 
intro00_win: # This file is used to launch ISQL sessions on Windows for test server with running
intro00_nix: # This file is used to launch ISQL sessions on POSIX for test server with running
intro00_25x_all: # Firebird 2.5.x
intro00_30x_all: # Firebird 3.x
intro00_40x_all: # Firebird 4.x 
intro00_50x_all: # Firebird 5.x 
intro00_win: # Parameters are extracted by '1run_oltp_emul.bat' command scenario.
intro00_win: # Text-based values can refer to OS environment variables or previously defined
intro00_win: # parameters using exclamation sign, e.g.:  some_parameter = !some_known_variable!
intro00_nix: # Parameters are extracted by '1run_oltp_emul.sh' command scenario.
intro00_win: # Text-based values can refer to OS environment variables or previously defined
intro00_win: # parameters using dollar sign, e.g.:  some_parameter = $some_evaluable_expression
intro00_all: ####################################################################

intro01_all: #::::::::::::::::::::::::::::::::::::::::::::::::
intro01_all: #  SETTINGS FOR START AND FINISH ISQL SESSIONS
intro01_all: #::::::::::::::::::::::::::::::::::::::::::::::::


fbc_all:    # Folder with Firebird console utilities (isql, fbsvcmgr, gfix, gbak).
fbc_all_nix:    # For builds that are published on official Firebird site such folder is /opt/firebird/bin/
fbc_all_nix:    # For builds that are installed from Ubuntu/Debian repository this folder is /usr/bin/
fbc_all:    # Trailing backslash is optional.
fbc_all_win:    # Example:
fbc_25x_win:    # fbc = C:\Firebird25\bin
fbc_30x_win:    # fbc = C:\Firebird30
fbc_40x_win:    # fbc = C:\Firebird40
fbc_50x_win:    # fbc = C:\Firebird50
fbc_all_nix:    # Examples:
fbc_all_nix:    # fbc = /opt/firebird/bin
fbc_all_nix:    # fbc = /usr/bin
fbc_all:    #
fbc_all:    # WARNING. DO NOT use names with spaces, parenthesis or non-ascii characters.
fbc_all_win:    # If FB binaries are in directory like "C:\Program files (x86)\Firebird Database Server" 
fbc_all_win:    # then make copy of this folder to something like C:\firebird.
fbc_all:    #
fbc_def_25x_win:    fbc = C:\Firebird25\bin
fbc_def_30x_win:    fbc = C:\Firebird30
fbc_def_40x_win:    fbc = C:\Firebird40
fbc_def_50x_win:    fbc = C:\Firebird50
fbc_def_nix:    fbc = /opt/firebird/bin


clu_all_nix:    # LINUX ONLY. OPTIONAL FOR CentOS/RH. Command-line utility for operate as ISQL.
clu_all_nix:    # Actual only for builds installed from Ubuntu/Debian repository.
clu_all_nix:    # These builds have ISQL utility with different name: 'isql-fb' instead of usual 'isql'.
clu_all_nix:    # Full name of this utility will be evaluated as concatenation of <fbc> and <clu> values.
clu_all_nix:    # String '<fbc>/isql' will be used to call ISQL if you leave this parameter commented.
clu_all_nix:    #
clu_all_nix:    # More details about used directories when FB is installed from Ubuntu/Debian repository:
clu_all_nix:    #     https://firebirdsql.org/manual/ubusetup.html
clu_all_nix:    #     https://www.firebirdsql.org/file/documentation/reference_manuals/user_manuals/html/ubusetup.html 
clu_all_nix:    # Command for list FB-related files that were installed on Ubuntu/Debian:
clu_25x_nix:    #     dpkg -L firebird2.5-classic or dpkg -L firebird2.5-superclassic
clu_30x_nix:    #     dpkg -L firebird3.0-server
clu_40x_nix:    #     dpkg -L firebird4.0-server
clu_50x_nix:    #     dpkg -L firebird5.0-server
clu_all_nix:    #
clu_def_nix:    # clu = isql-fb


dbnm_all:    # Full path and file name of database. DO NOT USE ALIAS. Use only ASCII characters.
dbnm_all_win:    # Existing OS variable can be referred here by enclosing it into exclamation marks.
dbnm_all_nix:    # Existing OS variable can be referred here by using dollar sign.
dbnm_all_nix:    # It is recommended to read Filesystem Hierarchy Standard before you decide where to put
dbnm_all_nix:    # database and temporary files:
dbnm_all_nix:    #     https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.pdf
dbnm_all:    # Firebird service account must have full access to the folder of specified database <dbnm>
dbnm_all:    # (test will try to create temporary database in this folder for some checks and then drop it).
dbnm_all:    #
dbnm_all:    # Examples:
dbnm_win:    # dbnm = C:\temp\oltp_%(fb)s.fdb
dbnm_win:    # dbnm = !TEMP!\oltp_%(fb)s.fdb
dbnm_nix:    # dbnm = /var/db/oltp_%(fb)s.fdb
dbnm_nix:    # dbnm = $TMP/data/oltp_%(fb)s.fdb
dbnm_all:    #
dbnm_all:    # WARNING. DO NOT use names with spaces, parenthesis or non-ascii characters.
dbnm_all:    #
dbnm_def_win:    dbnm = C:\data\oltp_%(fb)s.fdb
dbnm_def_nix:    dbnm = /var/db/oltp_%(fb)s.fdb


host_all:    # Parameters for remote connection and authentication.
host_all:    # Will be ignored by command scenario if FB runs in embedded mode.
host_all:    #
host_all:    # Host name or IP address of computer with running Firebird.
host_all:    #
host_def_all:    host = localhost


port_all:    # Port that is listening by Firebird instance on <host>.
port_all:    # In order to check which process is listening to selected port, type (locally on server):
port_win:    #     netstat -a -n -o -b -p TCP -p TCPv6 | findstr /i /c:"LISTENING" | findstr /i /c:<port>
port_win:    # Output will contain PID of process at last token. Put this value in the command:
port_win:    #     wmic process where "ProcessID=<PID>" get ExecutablePath /format:list
port_nix:    #     netstat --tcp --listening --program --numeric | grep <port>
port_nix:    # Output will contain PID of process at last token (delimited by '/'). Put this value in the command:
port_nix:    #     ps ax | grep " <PID>" | grep -v grep
port_nix:    #
port_nix:    # Ubuntu/Debian notes: if your FB instance was installed from repository then you can check port by
port_nix:    # issuing command:
port_nix:    #     grep -i "RemoteServicePort" /etc/firebird/<@.@>/firebird.conf
port_nix:    # - where <@.@> marks major FB version (2.5; 3.0; 4.0; 5.0).
port_all:    #
port_def_all:    port = 3050


usr_all:    # Login for connect to FB services and database. Account must have the same rights as SYSDBA.
usr_def_all:    usr = SYSDBA


pwd_all:    # Password for <usr>
pwd_def_all:    pwd = masterkey


tmpdir_all:    # Folder for storing .sql scenarios, STDOUT and STDERR logs of every working isql session.
tmpdir_all:    # Trailing backslash is optional.
tmpdir_all_win:    # Allows referencing to existing OS environment variable by enclosing it into exclamation marks.
tmpdir_all_nix:    # Allows referencing to existing OS environment variable by using dollar sign.
tmpdir_all_nix:    # Apropriate access must be granted to this directory before test start:
tmpdir_all_nix:    #     chown <your_linux_account>:firebird <tmpdir>
tmpdir_all:    # Examples:
tmpdir_all_win:    #     tmpdir = C:\temp\logs.oltp%(fb)s
tmpdir_all_win:    #     tmpdir = !temp!\logs.oltp%(fb)s
tmpdir_all_nix:    #     tmpdir = /var/tmp/logs.oltp%(fb)s
tmpdir_all_nix:    #     tmpdir = $TMP/logs.oltp%(fb)s
tmpdir_all:    #
tmpdir_all:    # WARNING. DO NOT use names with spaces, parenthesis or non-ascii characters.
tmpdir_all_win:    # If your TEMP variable is like "C:\Documents and Settings\User\Local Settings\Temp"
tmpdir_all_win:    # then do NOT use here reference to it (!temp!) and specify something like C:\TEMP instead.
tmpdir_all_win:    #
tmpdir_all_win:    # NOTE: test uses <tmpdir> for writing to lot of temporary files, mostly by issuing 'ECHO' command.
tmpdir_all_win:    # On some Windows versions writing to these files can be drastically slow because Windows Defender
tmpdir_all_win:    # checks every writing operation that is produced by 'ECHO' commands that are issued by batch scenario.
tmpdir_all_win:    # In this case consider adding folder <tmpdir> to the list of items that must be excluded from
tmpdir_all_win:    # Windows Defender Antivirus scan.
tmpdir_all_win:    # See instructions here:
tmpdir_all_win:    #    https://support.microsoft.com/en-us/help/4028485/windows-10-add-an-exclusion-to-windows-security
tmpdir_all_win:    # Registry key for folders that must be excluded:
tmpdir_all_win:    #    HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows Defender\Exclusions\Paths
tmpdir_all:    #
tmpdir_def_win:    tmpdir = C:\temp\logs.oltp%(fb)s
tmpdir_def_nix:    tmpdir = /var/tmp/logs.oltp%(fb)s


remove_isql_logs_all:    # Condition for removing or preserving ISQL logs in <tmpdir> after test finish.
remove_isql_logs_all:    # Possible values: always | never | if_no_severe_errors
remove_isql_logs_all:    # * 'always' means that logs will be removed after test finish regardless any result.
remove_isql_logs_all:    # * 'never' means that logs will be always preserved.
remove_isql_logs_all:    # * 'if_no_severe_errors' means that logs will be removed only if no severe exceptions occured during test.
remove_isql_logs_all:    # Test considers following Firebird-related exceptions as 'severe':
remove_isql_logs_all:    #    gdscode    description
remove_isql_logs_all:    #  ---------    -----------
remove_isql_logs_all:    #  335544321    string truncation: attempt to assign too long text into a string variable.
remove_isql_logs_all:    #  335544334    convert_error: conversion error from string
remove_isql_logs_all:    #  335544347    not_valid: validation error for column @1, value "@2".
remove_isql_logs_all:    #  335544349    no_dup: operation violates unique index
remove_isql_logs_all:    #  335544352    no_priv: no permission for @1 access to @2 @3
remove_isql_logs_all:    #  335544359    read_only_field: attempted update of read-only column @1
remove_isql_logs_all:    #  335544360    read_only_rel: attempted update of read-only table
remove_isql_logs_all:    #  335544361    read_only_trans: attempted update during read-only transaction
remove_isql_logs_all:    #  335544362    read_only_view: cannot update read-only view @1
remove_isql_logs_all:    #  335544466    foreign_key: violation of FOREIGN KEY constraint "@1" on table "@2".
remove_isql_logs_all:    #  335544472    login: your user name and password are not defined.
remove_isql_logs_all:    #  335544558    check_constraint: operation violates CHECK constraint on view or table.
remove_isql_logs_all:    #  335544665    unique_key_violation: operation violates PRIMARY or UNIQUE KEY constraint
remove_isql_logs_all:    #  335544838    foreign_key_target_doesnt_exist: attempt to insert/update field in child table with value which does not exists in parent table
remove_isql_logs_all:    #  335544839    foreign_key_references_present: attempt to delete parent record while child records exist and FK was declared without CASCADE clause
remove_isql_logs_all:    #  335544842    stack_trace
remove_isql_logs_all:    #  335544843    ctx_var_not_found: context variable @1 is not found in namespace SYSTEM
remove_isql_logs_all:    #
remove_isql_logs_all:    # NOTE: if FB crash occures during test run then value of this parameter will be ignored and all logs will be preserved.
remove_isql_logs_all:    # Recommended value: if_no_severe_errors
remove_isql_logs_all:    #
remove_isql_logs_def_all:    remove_isql_logs = if_no_severe_errors


intro02_all: #:::::::::::::::::::::::::::::
intro02_all: #  SETTINGS FOR WORKLOAD LEVEL
intro02_all: #:::::::::::::::::::::::::::::

working_mode_all:    # Test has several settings that define how much work should be done by each business action in average.
working_mode_all:    # All of them are considered as separate enumerations: when new ISQL session creates connection, it reads
working_mode_all:    # "entry" setting about selected workload level and then read all other settings for THIS workload level.
working_mode_all:    # Parameter 'working_mode' is mnemonic for these enumerations. Possible values for this parameter are:
working_mode_all:    # SMALL_01, SMALL_02, SMALL_03, MEDIUM_01, MEDIUM_02, MEDIUM_03, LARGE_01, LARGE_02, LARGE_03 and HEAVY_01
working_mode_all:    # In case of launching test from several machines ensure that all of them have the same value for this parameter.
working_mode_all:    # Completely new workload mode can be added to the test by editing file 'oltp_main_filling.sql', see there
working_mode_all:    # sub-section "Definitions for workload modes".
working_mode_all:    # WARNING: exception will raise on test startup if this value was mistyped and has no corresponding data in DB.
working_mode_all:    # CAUTION: assigning LARGE* or HEAVY* modes leads to extremely high workload! Do this only when you have really
working_mode_all:    # powerful server with lot of CPUs, huge RAM and very fast I/O system.
working_mode_all:    #
working_mode_all:    # Mnemonic name of workload mode (must be specified without quotes, case-insensitive):
working_mode_all:    #
working_mode_def_all:    working_mode = small_03


used_in_replication_all:    # If you plan this database be involved in replication, then one need to add primary keys
used_in_replication_all:    # to all persistent tables that can be changed during test work.
used_in_replication_all:    # Assign value of following parameter to 1 in order to apply all necessary changes to tables DDL
used_in_replication_all:    # (primary keys and triggers for some of tables).
used_in_replication_all:    # Setting value to 0 will DROP all changes that are unneeded when test runs without replication.
used_in_replication_all:    # This parameter can be changed 'on the fly': database recreation is NOT required, but in case
used_in_replication_all:    # when database has valuable size, changes will be applied not instantly.
used_in_replication_all:    #
used_in_replication_def_all:    used_in_replication = 0


actions_todo_before_reconnect_all:    # This parameter defines volume of work that will be done by each ISQL before it will detach from DB and reconnect.
actions_todo_before_reconnect_all:    # Normally in a production system frequency of reconnections must be low.
actions_todo_before_reconnect_all:    # Rather, each connection must do as much work as possible. Unfortunately, when ISQL does its work by executing
actions_todo_before_reconnect_all:    # script, one can not to check log of errors which occured during this execution. Some errors can require test
actions_todo_before_reconnect_all:    # to be prematurely stopped (e.g. if FB process crashed and it was reflected in firebird.log). But each session
actions_todo_before_reconnect_all:    # can found this only when ISQL finished. This mean that value of following parameter must belong to reasonable scope.
actions_todo_before_reconnect_all:    # For some (exotic) purposes when it is needed to increase frequency of reconnections one may to set it to 5...50.
actions_todo_before_reconnect_all:    # Recommended value: 300
actions_todo_before_reconnect_all:    #
actions_todo_before_reconnect_def_all:    actions_todo_before_reconnect = 300


max_cps_all:    # Maximal number of established connections per second when test STARTUP begins.
max_cps_all:    # Defines allowed rate of new attachments appearance for making workload grow smoothly.
max_cps_all:    #
max_cps_all:    # We have to limit RATE of requests for new attachments, especially when total count of launching ISQL sessions 
max_cps_all:    # is 1000 or more. Otherwise some of sessions will get failure on attempt to establish connection with text:
max_cps_all:    #     Statement failed, SQLSTATE = 08004
max_cps_all:    #     connection rejected by remote interface
max_cps_all:    # If value of this parameter less than 10 or greater than 100 then delays will not occur and all sessions will try to establish
max_cps_all:    # their attachments at the same time. This can be reason of "connection rejected" error.
max_cps_all:    # Otherwise:
max_cps_all:    # * if number of sessions not exceeds [max_cps] then delay will be evaluated as random value between 1 and 4 seconds.
max_cps_all:    # * if number of sessions greater that this parameter then delay will be evaluated as: 1 + session_id / <max_cps>
max_cps_all:    #
max_cps_win:    # NOTE. If you intend to launch more than 1000 sessions then consider to adjust Windows registry settings:
max_cps_win:    # * goto HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\TCPIP\Parameter
max_cps_win:    # * create a new REG_DWORD value with name: TcpTimedWaitDelay. Set it to 60.
max_cps_win:    # * create a new REG_DWORD value with name: MaxUserPort. Set it to 32768 (this defines ephemeral port range).
max_cps_nix:    # NOTE. If you intend to launch more than 1000 sessions then consider to adjust following settings in /etc/sysctl.conf:
max_cps_nix:    # net.core.somaxconn = 2000
max_cps_nix:    # net.core.netdev_max_backlog = 2000
max_cps_nix:    # net.core.tcp_max_syn_backlog = 2000
max_cps_nix:    # net.ipv4.ip_local_port_range = 15000 61000
max_cps_nix:    # net.ipv4.tcp_tw_reuse = 1
max_cps_nix:    # net.ipv4.tcp_max_tw_buckets = 1440000
max_cps_nix:    # See also:
max_cps_nix:    # http://lxr.linux.no/#linux+v3.2.8/Documentation/networking/ip-sysctl.txt#L111
max_cps_nix:    # http://lxr.linux.no/#linux+v3.2.8/Documentation/networking/ip-sysctl.txt#L284
max_cps_nix:    # http://lxr.linux.no/#linux+v3.2.8/Documentation/networking/ip-sysctl.txt#L464
max_cps_nix:    # https://www.centos.org/docs/5/html/5.1/Deployment_Guide/s3-proc-sys-net.html
max_cps_nix:    # http://docs.continuent.com/tungsten-clustering-6.0/performance-networking.html
max_cps_nix:    # https://access.redhat.com/solutions/41776
max_cps_all:    #
max_cps_all:    # Recommended value: 20...30
max_cps_all:    #
max_cps_def_all:    max_cps = 25


sleep_min_all:    # OPTIONAL.
sleep_min_all:    # MINIMAL pause duration between each business operations, in seconds.
sleep_min_all:    # This parameter has default value 0 and can be commented.
sleep_min_all:    # Duration of pause will be evaluated at runtime as random value 
sleep_min_all:    # between <sleep_min> and <sleep_max> values.
sleep_min_all:    #
sleep_min_def_all:    sleep_min = 0


sleep_max_all:    # MAXIMAL pause duration between each business operations, in seconds.
sleep_max_all:    # Default: 0 - no pauses, next transaction will start immediatelly after previous commit.
sleep_max_all:    # This leads to maximal (non-realistic) level of workload.
sleep_max_all:    # Delay statement will be inserted in .sql script by '1run_oltp_emul'; the form of this statement depends on value of
sleep_max_all:    # parameter 'sleep_ddl':
sleep_max_win:    # 1) If parameter 'sleep_ddl' is commented (undefined) then temporary .vbs script will be created in the <tmpdir> folder
sleep_max_win:    #    and Windows built-in utility 'cscript.exe' will be invoked with passing required delay to this .vbs:
sleep_max_win:    #    %systemroot%\system32\cscript.exe //nologo //e:vbscript //t:NNN <tmpdir>\<tmp_vbs> <sleep_max>
sleep_max_win:    #    This leads to excessive OS workload when number of sessions is more than ~300.
sleep_max_nix:    # 1) If parameter 'sleep_ddl' is commented (undefined) then OS call ("shell sleep <sleep_max>;") will be added after each
sleep_max_nix:    #    transaction commit in order to pause SQL execution.
sleep_max_nix:    #    This leads to excessive OS workload when number of sessions is more than ~300.
sleep_max_all:    # 2) Otherwise special UDF for delay will be invoked from separate execute block after each transaction commit.
sleep_max_all:    #    This UDF must be declared in SQL-script which name is defined by <sleep_ddl> parameter (see this config).
sleep_max_all:    #
sleep_max_all:    # NOTE. THIS PARAMETER IS MANDATORY AND CAN NOT BE COMMENTED.  SPECIFY 0 IF NO PAUSES REQUIRED.
sleep_max_all:    #
sleep_max_def_all:    sleep_max = 0


sleep_ddl_all:    # When we want to insert delays between subsequent business actions then parameter sleep_max > 0 must be specified.
sleep_ddl_win:    # Delays can be done either by external OS command (i.e. "shell cscript <vbs_scenario_for_delay> ;") or by UDF invocation.
sleep_ddl_nix:    # Delays can be done either by external OS command (i.e. "shell ... ;") or by UDF invocation.
sleep_ddl_all:    # Calls to external OS command from dozen of sessions leads to valuable load, especially when number of sessions more than 300.
sleep_ddl_all:    # This can be avoided if delays are done via UDF calls.
sleep_ddl_all:    #
sleep_ddl_all:    # Parameter 'sleep_ddl' specifies mame of .sql script with declaration of UDF for DELAYS between subsequent business actions.
sleep_ddl_all:    # Script must correctly drop old UDFs with any name that contains phrases: DELAY, SLEEP or PAUSE.
sleep_ddl_all:    # After dropping, script must create new UDF and test it (for checking results in log).
sleep_ddl_all:    # This script will be applied only when parameter 'sleep_max' greater than 0.
sleep_ddl_all:    # Note. The whole following phrase:
sleep_ddl_all:    #
sleep_ddl_all:    #     declare external function <UDF_name>
sleep_ddl_all:    #
sleep_ddl_all:    # -- must be written on the SINGLE LINE in this script ( <UDF_name> will be searched in this line as its 4th word).
sleep_ddl_all:    #
sleep_ddl_win:    # This UDF implementation (.dll file) must be stored in the server-side folder, usually in %FIREBIRD_HOME%\UDF.
sleep_ddl_nix:    # This UDF implementation (.so file) must be stored in the server-side folder, usually in $FIREBIRD_HOME$/UDF.
sleep_ddl_all:    # Also, UDF calls must be enabled in firebird.conf by specifying: UDFaccess = restrict UDF
sleep_ddl_nix:    # NOTES for Ubuntu/Debian.
sleep_ddl_nix:    #     If your FB instance was installed from Ubuntu/Debian repository then put .so file to /usr/lib/firebird/<@.@>/UDF/
sleep_ddl_nix:    #     where '@.@' marks major version of FB, i.e.:
sleep_ddl_25_nix:    #         /usr/lib/firebird/2.5/UDF/
sleep_ddl_3x_nix:    #         /usr/lib/firebird/3.0/UDF/
sleep_ddl_4x_nix:    #         /usr/lib/firebird/4.0/UDF/
sleep_ddl_nix:    #     UdfAccess parameter for such FB instance must have *absolute* value rather then relative, i.e.:
sleep_ddl_4x_nix:    #         UdfAccess = /usr/lib/firebird/<@.@>/UDF/
sleep_ddl_all:    # See description for parameter 'UDFaccess' in standard firebird.conf for details.
sleep_ddl_nix:    #
sleep_ddl_win:    # Test provides its own UDF and appropriate declaration script named: 'oltp_sleepUDF_win.sql'.
sleep_ddl_win:    # Unpack file .\util\udf64\SleepUDF.dll.zip and put file SleepUDF.dll in any folder that is allowed by
sleep_ddl_win:    # 'UDFaccess' parameter from firebird.conf.
sleep_ddl_nix:    # Test provides its own UDF and appropriate declaration script named 'oltp_sleepUDF_nix.sql'.
sleep_ddl_nix:    # Unpack file ./util/udf64/SleepUDF.so.tar.gz  and put file SleepUDF.so in any folder that is allowed by 'UDFaccess' parameter.
sleep_ddl_nix:    # from firebird.conf.
sleep_ddl_nix:    #
sleep_ddl_all:    # NOTES.
sleep_ddl_all:    #     UDF usage can not be avoided if parameter 'mon_unit_perf' has value 2. You can NOT leave 'sleep_ddl' commented out in this case.
sleep_ddl_40x_all:    #
sleep_ddl_40x_all:    #     By default, UDF usage is deprecated in Firebird 4.0+ and parameter UDFacces and absent in its firebird.conf.
sleep_ddl_40x_all:    #     You have to add it or uncomment manually.
sleep_ddl_50x_all:    #
sleep_ddl_50x_all:    #     By default, UDF usage is deprecated in Firebird 4.0+ and parameter UDFacces and absent in its firebird.conf.
sleep_ddl_50x_all:    #     You have to add it or uncomment manually.
sleep_ddl_all:    #
sleep_ddl_def_win:    sleep_ddl = .\oltp_sleepUDF_win.sql
sleep_ddl_def_nix:    sleep_ddl = ./oltp_sleepUDF_nix.sql


no_auto_undo_all:    # Should SET TRANSACTION statement include NO AUTO UNDO clause ? Avaliable values: 1=yes, 0=no
no_auto_undo_all:    # Performance can be increased if this option is set to 1:
no_auto_undo_all:    # SuperServer:   5 -  6 %%
no_auto_undo_all:    # SuperClassic: 10 - 11 %%
no_auto_undo_all:    # Recommended value: 1
no_auto_undo_all:    #
no_auto_undo_def_all:    no_auto_undo = 1


recalc_idx_min_interval_all:    # Minimal interval, in minutes, between two subsequent calls of service procedure 'srv_recalc_idx_stat' which updates index statistics.
recalc_idx_min_interval_all:    # Only indexes for tables that are participated in most often performing queries are affected. 
recalc_idx_min_interval_all:    # Note that frequent update of index statistics has sense only for small databases which have quickly changed data distribution.
recalc_idx_min_interval_all:    # There is no sense to update index statistics if test will runs for 1-2 hours and database has size more than 100 Gb: most probably
recalc_idx_min_interval_all:    # it will finish at the moment when test itself will also be close to expiration. 
recalc_idx_min_interval_all:    # In that case set value of this parameter to zero to prevent selection of procedure that does this updating.
recalc_idx_min_interval_all:    #
recalc_idx_min_interval_all:    # Recommended value of this parameter depends on size of database:
recalc_idx_min_interval_all:    #     within scope 30...60 minutes for databases with size up to 20 Gb;
recalc_idx_min_interval_all:    #     within scope 60...90 minutes for databases with size 20...40 Gb;
recalc_idx_min_interval_all:    #     within scope 90...120 minutes for databases with size 40...60 Gb;
recalc_idx_min_interval_all:    #     within scope 120...240 minutes for databases with size 60...80 Gb;
recalc_idx_min_interval_all:    #     0 (zero) for databases with size more than 80...100 Gb (this means that statistics will not be updated at all).
recalc_idx_min_interval_all:    # NOTE. For big databases (with size more than 100 Gb) updating of index statistics has sense only for big [test_time] values.
recalc_idx_min_interval_all:    #
recalc_idx_min_interval_def_all:    recalc_idx_min_interval = 30


use_es_all:    # Following parameter can be used for performance benchmark of Firebird ES/EDS mechanism and its External Connections Pool (ECP).
use_es_all:    # Note: ECP is supported only since Firebird 4.x. It is also supported by HQbird 3.x - commercial FB-branch (see https://ib-aid.com/ ).
use_es_all:    # This parameter is ignored if test is launched against Firebird 2.5.x.
use_es_all:    # When this parameter is non-zero then most of application and service procedures are changed: static PSQL expression are replaced with dynamic ones.
use_es_all:    # Avaliable values:
use_es_all:    #     0 - do not change static PSQL code, use it whenever it is possible (default);
use_es_all:    #     1 - replace static PSQL code with dynamic and use it in 'EXECUTE STATEMENT', but *without* using 'ON EXTERNAL' mechanism;
use_es_all:    #     2 - replace static PSQL code with dynamic and use it in 'EXECUTE STATEMENT ... ON EXTERNAL'.
use_es_all:    #         External Connections Pool can be tested and additional reports will be generated in this case.
use_es_all:    #
use_es_all:    # This parameter can be changed without need to DB recreation: test applies DDL replacements before every new launch.
use_es_all:    # If 'use_es' = 2 and 'separate_workers' = 1 then additional requirement exists for parameters 'mon_query_role', 'mon_usr_prefix' and 'mon_usr_passwd':
use_es_all:    # all of them must be defined, i.e. have non-empty values. Otherwise there is no way to distinguish "authors" of running DML within external connections.
use_es_all:    #
use_es_all:    # WARNING! Activating ES/EDS without ECP leads to significant performance penalty!
use_es_all:    # It is strongly recommended to enable ECP when this parameter is set to 2.
use_es_all:    #
use_es_all:    # Optimal values of ECP-related parameters in firebird.conf can be found empirically as follows:
use_es_all:    # 1. Set parameter 'make_html' of this test to 1 (this parameter is described below);
use_es_all:    # 2. Open firebird.conf and change ExtConnPoolSize: set it to 2*N+10, whene N is planning number of launched ISQL sessions;
use_es_all:    # 3. ExtConnPoolLifeTime: optimal value can be achieved after several FB restarts and test launches.
use_es_all:    #    Initial value can be set to 15.
use_es_all:    #    Then launch test with test_time not less than 20 minutes. Wait until it completely finish.
use_es_all:    #    Open HTML report and find there text: "External connections life activity, per connections". Note that there is 'chart' reference to the right of this text.
use_es_all:    #    Jump to this chart ("External connections pool: life activity, per connections").
use_es_all:    #    Note on dark-magenta dots that represent "Max. idle state in the pool, s".
use_es_all:    #    If almost all of them lie near upper bound of this chart then you have to INCREASE value of ExtConnPoolLifeTime parameter. Set it, for example, to 30.
use_es_all:    #    Restart FB, repeat test launch, wait for full completition and check again this chart.
use_es_all:    #    Do these steps until most of dark-magenta dots on Y-axis will be much lower than value of ExtConnPoolLifeTime.
use_es_all:    #
use_es_def_all:    use_es = 0


intro03_all: #:::::::::::::::::::::::::::::::::::
intro03_all: # SETTINGS RELATED TO LOCK CONFLICTS
intro03_all: #:::::::::::::::::::::::::::::::::::


separate_workers_all:    # When some session must change exicting document (rather than to create new), it chooses it using random selection.
separate_workers_all:    # This can lead to lot of UPDATE CONFLICTS between concurrent sessions, especially when number of documents is small.
separate_workers_all:    # Also, even when two sessions choose different documents but at least one of wares is the same, business actions can 
separate_workers_all:    # lead stock remainder for such ware become zero.
separate_workers_all:    # Further attempts to withdraw this ware lead to exception referring to inadmissible negative remainder.
separate_workers_all:    # This means that all previous work of this transaction was in vain and it has to rollback changes.
separate_workers_all:    #
separate_workers_all:    # We can separate sessions in such way that each of them will work within "sandbox" and never fall in conflict with
separate_workers_all:    # concurrent sessions for documents or stock remainders.
separate_workers_all:    #
separate_workers_all:    # Assign 1 to this parameter if you want to separate work of sessions and thus totally exclude exceptions related to
separate_workers_all:    # update conflicts and violation or check constraint defined for aggregated remainders value.
separate_workers_all:    # Otherwise set it to 0.
separate_workers_30x_all:    # NOTE. When this parameter is 1 and 'use_es' is 2 then all following parameters must be uncommented:
separate_workers_30x_all:    # 'mon_query_role' ; 'mon_usr_prefix' ; 'mon_usr_passwd'.
separate_workers_40x_all:    # NOTE. When this parameter is 1 and 'use_es' is 2 then all following parameters must be uncommented:
separate_workers_40x_all:    # 'mon_query_role' ; 'mon_usr_prefix' ; 'mon_usr_passwd'.
separate_workers_50x_all:    # NOTE. When this parameter is 1 and 'use_es' is 2 then all following parameters must be uncommented:
separate_workers_50x_all:    # 'mon_query_role' ; 'mon_usr_prefix' ; 'mon_usr_passwd'.
separate_workers_all:    # Recommended value: 1
separate_workers_all:    #
separate_workers_def_all:    separate_workers = 1


update_conflict_percent_all:    # How many documents from other's "sandboxes" can be taken in processing by 'this' ISQL session, percent.
update_conflict_percent_all:    # Value 0 means that we do not allow ISQL session to take any documents except those which was created by itself.
update_conflict_percent_all:    # Value 100 means that we require for each ISQL session take for processing only OTHER's documents. 
update_conflict_percent_all:    # Moreover, this also mean that we want ISQL session 'forget' about documents which were created by itself.
update_conflict_percent_all:    # This will lead to extremely high number of lock-conflicts and very poor performance.
update_conflict_percent_all:    # Recommened value: 0 - for benchmark purposes; 30...50 - for investigations.
update_conflict_percent_all:    #
update_conflict_percent_def_all:    update_conflict_percent = 0


unit_selection_method_all:    # How business operations should be selected: randomly or in predictable manner.
unit_selection_method_all:    # Allowed values:
unit_selection_method_all:    # random - on occasional basis, but with respect to priority/probability of business operatrions nature;
unit_selection_method_all:    # predictable - forcedly make every ISQL session to work using given sequence of business operations, i.e.
unit_selection_method_all:    #     create client order -> create order to supplier -> get invoice from supplier -> ...
unit_selection_method_all:    # Value 'predictable' was not deeply tested and currently can lead to poor performance.
unit_selection_method_all:    # See SP 'srv_random_unit_choice' for choising algorithm.
unit_selection_method_all:    # Recommened value: random
unit_selection_method_all:    #
unit_selection_method_def_all:    unit_selection_method = random


intro04_all: #::::::::::::::::::::::::::::::::::::
intro04_all: #  SETTINGS FOR ADDITIONAL LOGGING 
intro04_all: #::::::::::::::::::::::::::::::::::::


detailed_info_all:    # Do we add in ISQL logs detailed info for each actions that was registered while current transaction was performed ?
detailed_info_all:    # Note: value = 1 significantly increases disk I/O on client machine.
detailed_info_all:    # Do not use it if you are not interested on these data.
detailed_info_all:    # Recommended value: 0
detailed_info_all:    #
detailed_info_def_all:    detailed_info = 0


use_mtee_win:    # WINDOWS ONLY.
use_mtee_win:    # Exceptions that will raise during test work do not have timestamp information.
use_mtee_win:    # This can make it difficult to find the causes of errors.
use_mtee_win:    # One may to use console splitter MTEE.EXE that has ability to prefix each STDOUT/STDERR line
use_mtee_win:    # with exact timestamp. You do not have to search or install this utility: it is already supplied
use_mtee_win:    # with this test in .zip file and will be extracted if needed to the folder defined by <tmpdir>
use_mtee_win:    # parameter of this config.
use_mtee_win:    # Following parameter sets how MTEE console splitter will be used:
use_mtee_win:    #     0 - do not use console splitter (default)
use_mtee_win:    #     1 - provide timestamp prefix only for messages that goes to STDERR before saving this stream;
use_mtee_win:    #     2 - provide timestamp prefix only for all messages and MERGE data of STDERR with STDOUT.
use_mtee_win:    #
use_mtee_win:    # It is recommended to change this parameter only for debug/research purposes. Normally it must be 0.
use_mtee_win:    #
use_mtee_def_win:    use_mtee = 0


mon_unit_perf_all:    # Setting for enabling queries to monitor tables in order to make detailed performance analysis.
mon_unit_perf_all:    # When 0 then monitor tables are not queried.
mon_unit_perf_all:    # When 1 then EVERY session will take two snapshots before and after execution of selected unit.
mon_unit_perf_all:    # More detailed analysis with detalization down to separate stored procedures can be achieved
mon_unit_perf_all:    # by updating setting 'mon_unit_list'.
mon_unit_perf_all:    # When 2 then only ONE session is dedicated to gather monitoring data with obtaining data
mon_unit_perf_all:    # that relates to ALL other working sessions. This is first session of launched.
mon_unit_perf_all:    # It will call special SP 'srv_fill_mon_memo_consumption' every <mon_query_interval>-th second.
mon_unit_perf_all:    # NOTE: delays for mon_unit_perf=2 between transactions will be done only when 'sleep_ddl' is defined,
mon_unit_perf_all:    # e.g. when we make delays via UDF, without calls to external OS commands.
mon_unit_perf_40x_all:    # By default, UDF usage is deprecated in Firebird 4.0+ and parameter UDFacces and absent in its firebird.conf.
mon_unit_perf_40x_all:    # You have to add it or uncomment manually.
mon_unit_perf_50x_all:    # By default, UDF usage is deprecated in Firebird 4.0+ and parameter UDFacces and absent in its firebird.conf.
mon_unit_perf_50x_all:    # You have to add it or uncomment manually.
mon_unit_perf_all:    #
mon_unit_perf_def_all:    mon_unit_perf = 0



mon_query_role_all:    # Following three parameters must be either all defined or all commented out.
mon_query_role_all:    # They are used for two purposes:
mon_query_role_all:    # 1) to gather monitoring data on behalf of non-privileged user about resources that were consumed by him and ONLY by him;
mon_query_role_all:    # 2) to link "authority" of DML with worker ID. Need only when this DML is performed by connection in External Pool and
mon_query_role_all:    #    changes of every worker must be separated (see description of parameters 'separate_workers' and 'use_es').
mon_query_role_all:    #
mon_query_role_all:    # Gathering of monitoring data leads to significant performance penalty if session works as SYSDBA: 
mon_query_role_all:    # all other attachments have to put information about their state into special pool.
mon_query_role_all:    # Benchmarks show that performance can fall for ~10x when all attachments work as SYSDBA and value of
mon_query_role_all:    # parameter <mon_unit_perf> is 1 (i.e. every worker gathers monitoring data about himself *AND* all other workers).
mon_query_role_all:    # But actually each worker is interested only about its own data from monitoring rather than others.
mon_query_role_all:    #
mon_query_role_all:    # Engine was improved in Firebird 3.x+ for such case: if session works as NON-privileged used then
mon_query_role_all:    # its query to monitoring tables will not affect on other attachments which work under different logins.
mon_query_role_all:    # One can use this improvement and require that test will launch every ISQL session so that it will work
mon_query_role_all:    # with database as non-privileger user, with accessing to DB objects via special role with all needed grants.
mon_query_role_all:    #
mon_query_role_all:    # Parameter 'mon_query_role' specifies name of this role. If it is specified then test will create such role
mon_query_role_all:    # and give it all grants that are needed for normal work. This role will be further granted to all non-privileged
mon_query_role_all:    # users which are also created by test. Parameter 'mon_usr_prefix' must also be specified in this case.
mon_query_role_all:    # If 'mon_query_role' is commented then all sessions will work as SYSDBA.
mon_query_role_all:    # NOTE: actual only for Firebird 3.0 and above. Has no effect on Firebird 2.5.
mon_query_role_all:    # Recommended value: any string that meets FB requirement to the name of ROLE, e.g.: tmp$oemul$worker
mon_query_role_all:    #
mon_query_role_def_all:    mon_query_role = tmp$oemul$worker

mon_usr_prefix_all:    # Prefix for each name of temporarily created users for work with database.
mon_usr_prefix_all:    # Each user name will be further provided with suffix like '0001', '0002' etc, up to the total number of sessions.
mon_usr_prefix_all:    # These users will be granted to use ROLE which name is defined by <mon_query_role> parameter (see above).
mon_usr_prefix_all:    # After test finish all of them will be dropped.
mon_usr_prefix_all:    # NOTE-1. Actual only for Firebird 3.0 and above. Has no effect on Firebird 2.5.
mon_usr_prefix_all:    # NOTE-2. Value must end with underscore character.
mon_usr_prefix_all:    # Recommended value: any string that meets FB requirement to the name of USER, e.g.: tmp$oemul$user_
mon_usr_prefix_all:    #
mon_usr_prefix_def_all:    mon_usr_prefix = tmp$oemul$user_

mon_usr_passwd_all:    # Password for temporarily created users. Do not set this it to trivial value because policy for passwords
mon_usr_passwd_all:    # can became more strict in the future versions of FB.
mon_usr_passwd_all:    # Value must not contain '=', '!' and '%%' character because of parsing problems.
mon_usr_passwd_all:    #
mon_usr_passwd_def_all:    mon_usr_passwd = 0Ltp-Emu1


mon_unit_list_all:    # This setting can be used only when config parameter 'enable_mon_query' is 1.
mon_unit_list_all:    # List of top-level units (see 'business_ops' table) which performance statistics we want 
mon_unit_list_all:    # to be logged by querying  monitoring tables. Logging is done by SP srv_log_mon_for_traced_units.
mon_unit_list_all:    # Value can be single unit name or LIST of unit names delimited by forward slash.
mon_unit_list_all:    # Example:
mon_unit_list_all:    #     sp_make_qty_storno/sp_kill_qty_storno/sp_multiply_rows_for_qdistr/sp_multiply_rows_for_pdistr
mon_unit_list_all:    # Default value: // (two slashes) without any characters between them, i.e. no interested units for logging.
mon_unit_list_all:    #
mon_unit_list_def_all:    mon_unit_list = //


mon_query_interval_all:    # This setting is applied only when config parameter 'enable_mon_query' is 2.
mon_query_interval_all:    # Number of seconds between calls to SP that gathers monitoring data for all working attachments.
mon_query_interval_all:    # Monitor data will be gathered only by single (dedicated) isql session which is launched first.
mon_query_interval_all:    # Parameter 'sleep_ddl' must be uncommented and its value has to point on existent SQL script
mon_query_interval_all:    # with UDF declaration that implements delay.
mon_query_interval_all:    # Actual duration of delay, in seconds, will be evaluated as minimal of <mon_query_interval>
mon_query_interval_all:    # and <test_time> * 60 divided by 20.
mon_query_interval_all:    #
mon_query_interval_def_all:    mon_query_interval = 60


qmism_verify_bitset_all:    # How stock remainders should be verified BEFORE totalling turnovers (see procedure 'sp_make_invnt_saldo').
qmism_verify_bitset_all:    #
qmism_verify_bitset_all:    # Declarative CHECK constraint for non-negative QTY_* columns should NOT ever be fired in this test.
qmism_verify_bitset_all:    # This parameter defined numeric value which bits must be interpreted as:
qmism_verify_bitset_all:    #     bit 0 := 1 -- perform calls of procedure SRV_FIND_QD_QS_MISM in order to register mismatches between
qmism_verify_bitset_all:    #                   doc_data.qty and total number of rows in QDISTR and QSTORNED tables for doc_data.id;
qmism_verify_bitset_all:    #     bit 1 := 1 -- perform calls of procedure SRV_CHECK_NEG_REMAINDERS instead of actual totalling turnovers
qmism_verify_bitset_all:    #                   to the table INVNT_SALDO. This value must be used only for debug purposes.
qmism_verify_bitset_all:    #     bit 2 := 1 -- allow dump dirty data into debug tables for analysis, see sp ZDUMP4DBG, in case
qmism_verify_bitset_all:    #                   when PK/FK or check constraint is violated (see also parameter 'halt_test_on_errors')
qmism_verify_bitset_all:    #                   NOTE: when bit#2 has value 1 then parameter 'create_with_debug_objects' must be 1
qmism_verify_bitset_all:    #                   to force build scenario create auxiliary Z-tables.
qmism_verify_bitset_all:    #
qmism_verify_bitset_all:    # This parameter was used during test development and can be useful in case of some changes/refactoring
qmism_verify_bitset_all:    # in test logic. Normally its value must be 1.
qmism_verify_bitset_all:    #
qmism_verify_bitset_def_all:    qmism_verify_bitset = 1


trc_unit_perf_win:    # WINDOWS ONLY.
trc_unit_perf_win:    # Should 1st of launching ISQL instances also start asynchronously FBSVCMGR with opening TRACE session ?
trc_unit_perf_win:    # If yes then final report will have result of parsing trace log for that ISQL session activity with
trc_unit_perf_win:    # aggregate data about each business action. Also, average values will be calculated for:
trc_unit_perf_win:    # 1) speed of fetches and marks per second;
trc_unit_perf_win:    # 2) ratios reads / fetches and writes / marks.
trc_unit_perf_win:    # These values will be divided for 10 equal time intervals in order to see changes 
trc_unit_perf_win:    # in performance that could occur during <test_time> phase of test.
trc_unit_perf_win:    # There is no performance penalty when single trace session is active so one may safely
trc_unit_perf_win:    # to set this value to 1. Note though that if you will interrupt test by brute kill all
trc_unit_perf_win:    # ISQL sessions than you have also to kill process of FBSVCMGR which can remain active.
trc_unit_perf_win:    # Currently implemented only for Windows.
trc_unit_perf_win:    #
trc_unit_perf_def_win:    trc_unit_perf = 0


intro05_all: #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
intro05_all: #  SETTINGS FOR PREMATURE TERMINATION OF WORK BEFORE TIME EXPIRE
intro05_all: #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::


halt_test_on_errors_all:    # Mnemonics of exceptions which must force test to be stopped (see calls of fn_halt_sign(gdscode)):
halt_test_on_errors_all:    #     'CK' -- halt if CHECK violation or 'not_valid' occurs (mostly this can be due to negative stock remainders)
halt_test_on_errors_all:    #     'PK' -- halt if PK or UK violation occurs
halt_test_on_errors_all:    #     'FK' -- halt if FK violation occurs // now n/a because test does not use foreign keys.
halt_test_on_errors_all:    #     'ST' -- halt if gdscode 335544842 appeared at the top of stack and logged into perf_log (strange problem only in 3.0 SC)
halt_test_on_errors_all:    # These mnemonics can be combined in list, i.e.: 'CK/PK/FK' - halt if CHECK or PK or FK violation occurs
halt_test_on_errors_all:    # Default: '/CK/' ==> force test to be stopped on attempt to write NEGATIVE values for stock remainders.
halt_test_on_errors_all:    # 12.02.2015: PK and FK violations *can* be detected only during heavy workload in procedures that operates with huge number
halt_test_on_errors_all:    # of records. These are: sp_make_qty_storno and sp_kill_qty_storno,
halt_test_on_errors_all:    # This can occur due to undefined order of UNDO actions inside the engine when some action must be cancelled.
halt_test_on_errors_all:    # Detailed investigation:
halt_test_on_errors_all:    #     sql.ru/forum/1142271/posledstviya-nepredskazuemo-neposledovatelnyh-otkatov-izmeneniy-pri-exception
halt_test_on_errors_all:    # Explanation by dimitr was sent privately to e-mail, letters date = 12.02.2015.
halt_test_on_errors_all:    #
halt_test_on_errors_def_all:    halt_test_on_errors = /CK/


use_external_to_stop_all:    # OPTIONAL.
use_external_to_stop_all:    # Parameter 'use_external_to_stop' defines name of text file that can be used for premature stop all working isql sessions.
use_external_to_stop_all:    # This parameter is NOT required, i.e. it can be commented. In this case test can be stopped by running temporary script
use_external_to_stop_win:    # '!tmpdir!/1stoptest.tmp.bat' which is created every time when test starts by script '1run_oltp_emul.bat'.
use_external_to_stop_nix:    # '$tmpdir/1stoptest.tmp.sh' which is created every time when test starts by script '1run_oltp_emul.sh'.
use_external_to_stop_all:    # This script works normally for most cases except extremely high workload when establishing of new connect is difficult.
use_external_to_stop_all:    #
use_external_to_stop_all:    # When extremely high workload is used then following message can appear on every attempt to establish new attachment:
use_external_to_stop_all:    #     Statement failed, SQLSTATE = 08004
use_external_to_stop_all:    #     connection rejected by remote interface
use_external_to_stop_all:    #
use_external_to_stop_all:    # In such case it can be more reliable to use EXTERNAL TABLE (i.e. TEXT FILE) to make all attachments to stop their work. 
use_external_to_stop_all:    # This is so because every running session 'looks' from time to time into this external table and checks existense of at 
use_external_to_stop_all:    # least one record in it. So, test will be quickly self-stopped when at least one non-empty line exists there. 
use_external_to_stop_all:    # Please note that you have to make this file EMPTY before every new test run. Test can not do that when server is remote.
use_external_to_stop_all:    #
use_external_to_stop_all:    # If you have decided to use EXTERNAL FILE then following steps must be done for premature terminate all test activity:
use_external_to_stop_all:    #     1. Open that file in text editor and type one ascii-character there;
use_external_to_stop_all:    #     2. Press ENTER and save this file.
use_external_to_stop_all:    #     3. Make this file empty again when all isql sessions terminated their work.
use_external_to_stop_all:    # Also, please note on value of parameter "ExternalFileAccess" in firebird.conf:
use_external_to_stop_all:    #     1. When ExternalFileAccess = FULL then 'use_external_to_stop' must be full path and name of text file that will be 
use_external_to_stop_all:    #        queried by every attachment as 'stop flag'.
use_external_to_stop_all:    #     2. When ExternalFileAccess = RESTRICTED then 'use_external_to_stop' must be only NAME of file, without path.
use_external_to_stop_all:    #
use_external_to_stop_win:    # By default this parameter is UNDEFINED, i.e. only temporary batch can be used for stop test prematurely:
use_external_to_stop_win:    #     <tmpdir>\1stoptest.tmp.bat 
use_external_to_stop_nix:    #     <tmpdir>/1stoptest.tmp.sh
use_external_to_stop_all:    #


intro06_all: #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
intro06_all: #  SETTINGS FOR DATABASE CREATION PROCESS AND INITIAL DATA FILLING 
intro06_all: #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
intro06_all:     #
intro06_all:     # *** NOTE *** 
intro06_all:     # Following settings except 'create_with_fw' and 'create_with'sweep'
intro06_all:     # will be IGNORED if database exists and has required number of documents.
intro06_all:     # If parameter 'host' is one of: {'localhost', '127.0.0.1'} then current
intro06_all:     # values of 'create_with_fw' and 'create_with'sweep' will be applied to DB
intro06_all:     # every time before launching ISQL sessions.


create_with_fw_all:    # Setting for FORCED WRITES attribute which must be written in the DB header before all sessions launch.
create_with_fw_all:    # Value can be one of: sync | async
create_with_fw_all:    # RECOMMENDED value:
create_with_fw_all:    #     sync - if you want to test performance for database that is not involved in replication;
create_with_fw_all:    #     async - if you plan to use DB which will be replicated to other host.
create_with_fw_all:    #             (note that in such case you must set parameter 'used_in_replication' to 1).
create_with_fw_win:    # When value is 'async', ensure that firebird.conf contains following uncommented parameters:
create_with_fw_win:    #     MaxUnflushedWrites = -1
create_with_fw_win:    #     MaxUnflushedWriteTime = -1
create_with_fw_all:    #
create_with_fw_def_all:    create_with_fw = sync


create_with_sweep_all:    # Setting for SWEEP INTERVAL which causes auto sweep start.
create_with_sweep_all:    # Value must be not less than -1.
create_with_sweep_all:    # Value -1 means that default value (20000) will be written into DB header.
create_with_sweep_all:    # Sweep starts when OST-OIT more than this threshold. Value 0 disables sweep.
create_with_sweep_all:    #
create_with_sweep_all:    # RECOMMENDED value for create_with_sweep is 0 (zero).
create_with_sweep_all:    # Sweep start can lead to unpredictable affect on performance, especially for short test duration.
create_with_sweep_all:    #
create_with_sweep_def_all:    create_with_sweep = 0


wait_if_not_exists_all:    # Should script be paused if database does not exist or its creation
wait_if_not_exists_all:    # did not finished properly (e.g. was interrupted; 1=yes; 0=no) ?
wait_if_not_exists_all:    # You have to set this parameter to 0 if this batch is launched by 
wait_if_not_exists_all:    # scheduler on regular basis. Otherwise it is recommended to set 1.
wait_if_not_exists_all:    #
wait_if_not_exists_def_all:    wait_if_not_exists = 0


wait_after_create_all:    # Should script be paused after creation database objects before starting
wait_after_create_all:    # initial filling with <init_docs> documents (mostly need only for debug; 1=yes, 0=no) ?
wait_after_create_all:    #
wait_after_create_def_all:    wait_after_create = 0


init_docs_all:    # Number of documents, total for all their types, needed for initial data population.
init_docs_all:    # Command scenario will compare number of existing document with this
init_docs_all:    # and create new ones only if {init_docs] still greater than obtained.
init_docs_all:    #
init_docs_all:    # *** NOTE *** THIS VALUE IS OBSOLETE, LEAVE IT EQUAL TO 0 (ZERO) ***
init_docs_all:    #
init_docs_all:    # Instead of generating dosuments by single attachment it is much more properly (and faster) to assign some big value 
init_docs_all:    # to 'warm_time' parameter (say, 1440 which means to run for 1 day) and also set 'test_time' to 0 (zero). 
init_docs_all:    # When size of database will reach value that you consider as enough then just stop the test by running batch 
init_docs_win:    # '!tmpdir!\1stoptest.tmp.bat' which always is created when test starts.
init_docs_nix:    # '$tmpdir/1stoptest.tmp.sh' which always is created when test starts.
init_docs_all:    #
init_docs_def_all:    init_docs = 0


expected_workers_all:    # This parameter actual only when 'init_docs' greater than 0 and 'separate_workers' is 1, i.e. when you want to separate 
expected_workers_all:    # each ISQL session in such way that they will not ever meet update conflicts during work. In other cases value if this
expected_workers_all:    # parameter is ignored.
expected_workers_all:    # If you decide to generate initial quantity of documents by using old 'init_docs' value then assign to 'expected_workers' 
expected_workers_all:    # value that is equal to the  number of ISQL sessions that is expected to run.
expected_workers_all:    #
expected_workers_def_all:    expected_workers = 100


init_buff_all:    # Actual only when 'init_docs' greater than 0 and FB mode is Classic Server or SuperClassic. Will be ignoired in SuperServer.
init_buff_all:    # Number of pages for usage during init data population ("-c" switch for ISQL). Used ONLY during phase of initial data population.
init_buff_all:    # Make sure that it is LESS than FileSystemCacheThreshold, which default is 65536.
init_buff_all:    #
init_buff_all:    # *** NOTE *** THIS VALUE IS OBSOLETE, LEAVE IT EQUAL TO 10000 ***
init_buff_all:    #
init_buff_def_all:    init_buff = 4096


wait_for_copy_all:    # Actual only when 'init_docs' greater than 0
wait_for_copy_all:    # Should command scenario (1run_oltp_emul) be PAUSED after finish creating
wait_for_copy_all:    # required initial number of documents (see parameter 'init_docs'; 1=yes, 0=no) ?
wait_for_copy_all:    # Value = 1 can be set if you want to make copy of .fdb and restore later
wait_for_copy_all:    # this database to 'origin' state. This can save time because of avoiding need
wait_for_copy_all:    # to create [init_docs] again:
wait_for_copy_all:    #
wait_for_copy_def_all:    wait_for_copy = 0


create_with_debug_objects_all:    # Do we want to create some DEBUG objects (tables, views and procedures)
create_with_debug_objects_all:    # in order to:
create_with_debug_objects_all:    # 1) make dumps of all data from tables when critical error occurs;
create_with_debug_objects_all:    # 2) make miscelaneous diagnostic queries via "Z_" views.
create_with_debug_objects_all:    # Value=1 will cause "oltp_misc_debug.sql" be called when build database.
create_with_debug_objects_all:    # NB: setting 'QMISM_VERIFY_BITSET' must have bit #2 = 1 when this value = 1.
create_with_debug_objects_all:    # (see oltp_main_filling.sql)
create_with_debug_objects_all:    # Recommended value: 1
create_with_debug_objects_all:    #
create_with_debug_objects_def_all:    create_with_debug_objects = 1


create_with_split_heavy_tabs_all:    # Test has two tables which are subject of very intensive modifications: QDistr and QStorned.
create_with_split_heavy_tabs_all:    # Performance highly depends on time which engine spends on handling DP, PP and index pages
create_with_split_heavy_tabs_all:    # of this tables - they are "bottlenecks" of schema. Database can be created either with two
create_with_split_heavy_tabs_all:    # these tables or with several "clones" of them (with the same stucture). The latter allows
create_with_split_heavy_tabs_all:    # to "split" workload on different areas and reduce low-level lock contention.
create_with_split_heavy_tabs_all:    # Should heavy-loaded tables (QDistr and QStorned) be splitted on several different tables,
create_with_split_heavy_tabs_all:    # each one for separate pair of operations that are 'source' and 'target' of storning ?
create_with_split_heavy_tabs_all:    # Avaliable values: 
create_with_split_heavy_tabs_all:    #     0 = do NOT split workload on several tables (instead of single QDistr and QStorned);
create_with_split_heavy_tabs_all:    #     1 = USE several tables with the same structure in order to split heavy workload on them.
create_with_split_heavy_tabs_all:    #         NOTE (2019). Not only Qdistr and QStorned but also PERF_LOG table will be 'splitted' onto
create_with_split_heavy_tabs_all:    #         several tables (with names PERF_SPLIT_01...PERF_SPLIT_09) when this parameter is set to 1. 
create_with_split_heavy_tabs_all:    # Recommended value: 1.
create_with_split_heavy_tabs_all:    #
create_with_split_heavy_tabs_def_all:    create_with_split_heavy_tabs = 1


create_with_separate_qdistr_idx_all:    # Whether heavy-loaded table (QDistr or its XQD_* clones) should have only one ("wide")
create_with_separate_qdistr_idx_all:    # compound index or two separate indices (1=yes, 0=no).
create_with_separate_qdistr_idx_all:    # Number of columns in compound index depends on value of two parameters:
create_with_separate_qdistr_idx_all:    #     1) 'create_with_split_heavy_tabs' and
create_with_separate_qdistr_idx_all:    #     2) 'create_with_separate_qdistr_idx' (this).
create_with_separate_qdistr_idx_all:    # Order of columns is defined by parameter 'create_with_compound_idx_selectivity'.
create_with_separate_qdistr_idx_all:    # Recommended value: 0.
create_with_separate_qdistr_idx_all:    #
create_with_separate_qdistr_idx_def_all:    create_with_separate_qdistr_idx = 0


create_with_compound_columns_order_all:    # Parameter 'create_with_compound_columns_order' defines order of fields in the starting part
create_with_compound_columns_order_all:    # of compound index key for the table which is subject to most heavy workload - QDistr. 
create_with_compound_columns_order_all:    # Avaliable options:
create_with_compound_columns_order_all:    #     'most_selective_first' or
create_with_compound_columns_order_all:    #     'least_selective_first'.
create_with_compound_columns_order_all:    # When choice = 'most_selective_first' then first column of this index will have selectivity = 1 / [W],
create_with_compound_columns_order_all:    # where [W] = number of rows in the table 'WARES', depends on selected workload mode.
create_with_compound_columns_order_all:    # Second and third columns will have poor selectivity = 1/6.
create_with_compound_columns_order_all:    # When choice = 'least_selective_first' then first and second columns will have poor selectivity = 1/6,
create_with_compound_columns_order_all:    # and third column will have selectivity = 1 / [W].
create_with_compound_columns_order_all:    #
create_with_compound_columns_order_all:    # Actual only when create_with_split_heavy_tabs = 0.
create_with_compound_columns_order_all:    # Recommended value: most_selective_first
create_with_compound_columns_order_all:    #
create_with_compound_columns_order_def_all:    create_with_compound_columns_order = most_selective_first


intro07_all: #:::::::::::::::::::::::::::::::::::::::::::::::::::::
intro07_all: #  SETTINGS FOR SCHEDULED-BASIS JOB AND TEST REPORT
intro07_all: #:::::::::::::::::::::::::::::::::::::::::::::::::::::

warm_time_all:    # Number of minutes since test launch for which evaluation of performance score is omited because database is 'cold' (not in cache).
warm_time_all:    # Means the same as 'ramp-up' period in TPC-C specification: we have to allow all sessions to establish  attachments and read some
warm_time_all:    # data into Firebird page cache.
warm_time_all:    # Recommended value: DBSize_Gb/2, where DBSize_Gb is size of database in Gb, but not less than 30 minutes.
warm_time_all:    # To estimate whether value of this parameter is apropriate, run test for 2-3 hours and look after its finish in report 
warm_time_all:    # "Performance per minute". Performance counter at the end of <warm_time> period must be close to values for subsequent 20-30 minutes.
warm_time_all:    # See also TPC-C specification rev 5.11:
warm_time_all:    # * 5.6.4 (page 78) - graphical explanation of ramp-up period;
warm_time_all:    # * Appendix C (page 132) - numerical quantities summary.
warm_time_all:    #
warm_time_def_all:    warm_time = 30


test_time_all:    # Duration of main test phase which starts after 'ramp-up'. Means the same as 'measurement interval' in TPC-C specification.
test_time_all:    # Overall performance score is evaluated as total number of successfully completed transactions during this phase divided by <test_time>.
test_time_all:    # At the end of this phase test will stop itself, i.e. you do not have to interrupt ISQL sessions.
test_time_all:    # Note that TPC-C requires minimum 120 minutes for this phase, but your system must allows to run test during 480 minutes - and this
test_time_all:    # value does not include <warm_time> phase (see TPC-C rev 5.1, 5.5.2.1, page 75).
test_time_all:    # ATTENTION. Reports and performance score for test_time less than 120 minutes must be considered as unreliable (doubtful).
test_time_all:    # Recommended value: at least 180.
test_time_all:    #
test_time_def_all:    test_time = 180


test_intervals_all:    # OBSOLETE. WILL BE REMOVED LATER.
test_intervals_all:    # This parameter used earlier for one of reports which was removed.
test_intervals_all:    # Currently its value will be ignored.
test_intervals_all:    #
test_intervals_def_all:    test_intervals = 30

results_storage_fbk_all:    # OPTIONAL.
results_storage_fbk_all:    # Backup(!) name of dedicated database that serves as storage for test settings
results_storage_fbk_all:    # and final report of every completed test.
results_storage_fbk_all:    # When test finished, this backup is restored to temporary database, new data are saved
results_storage_fbk_all:    # and then this database is backed up again to this .fbk.
results_storage_fbk_all:    #
results_storage_fbk_all:    # Scenario 'oltp_overall_report' (see 'utils' sub-directory) will restore from this backup
results_storage_fbk_all:    # for generating overall report, so in that case this parameter must be defined.
results_storage_fbk_all:    #
results_storage_fbk_all:    # Firebird service account must have access rights to operate with this file.
results_storage_fbk_all:    # It is recommended to put this .fbk in the same directory as <dbnm>.
results_storage_fbk_all:    #
results_storage_fbk_all:    # NOTE: *BACKUP* must be speficied here rather then .fdb file!
results_storage_fbk_all:    #
results_storage_fbk_all:    # Examples:
results_storage_fbk_win:    # results_storage_fbk = C:\data\oltp_%(fb)s-results-storage.fbk
results_storage_fbk_nix:    # results_storage_fbk = $(dirname "$dbnm")/oltp_%(fb)s_results.fbk
results_storage_fbk_nix:    # results_storage_fbk = /var/db/oltp_%(fb)s-results-storage.fbk
results_storage_fbk_all:    #


report_compress_cmd_all_nix:    # OPTIONAL. LINUX ONLY.
report_compress_cmd_all_nix:    # Utility to compress HTML report and (if FB crash occured) stack trace of dump.
report_compress_cmd_all_nix:    # Compressed result will be saved in the database defined by <results_storage_fbk>.
report_compress_cmd_all_nix:    # By default, GZIP utility will be used that must present on most Linux instances.
report_compress_cmd_all_nix:    # Supported compressors: gzip, p7zip, zstd and zip
report_compress_cmd_all_nix:    # If none of them can be found then HTML report will be stored without compression.
report_compress_cmd_all_nix:    # Extraction of HTML report will be done by 'oltp_overall_report' scenario which supposes
report_compress_cmd_all_nix:    # that apropriate packages already was installed, namely:
report_compress_cmd_all_nix:    #     'gzip'  - to extract from .gz; binary for extraction: /usr/bin/7za
report_compress_cmd_all_nix:    #     'p7zip' - to extract from .7z, .gz and .zip; binary for extraction: /usr/bin/7za
report_compress_cmd_all_nix:    #     'zstd'  - to extract from .zstd; binary for extraction: /usr/bin/zstd
report_compress_cmd_all_nix:    # Note that 7za and zstd provide much higher compression than ZIP or GZIP.
report_compress_cmd_all_nix:    # This parameter can be left commented out if you don't plan to run test on regular basis
report_compress_cmd_all_nix:    # with transferring its (compressed) results to scenario 'oltp_overall_report'.
report_compress_cmd_all_nix:    #
report_compress_cmd_all_nix:    # Examples:
report_compress_cmd_all_nix:    # report_compress_cmd=/usr/bin/gzip
report_compress_cmd_all_nix:    # report_compress_cmd=/usr/bin/7za
report_compress_cmd_all_nix:    # report_compress_cmd=/usr/bin/zstd
report_compress_cmd_all_nix:    # report_compress_cmd=/usr/bin/zip
report_compress_cmd_all_nix:    #


report_compressor_all_win:    # OPTIONAL. WINDOWS ONLY.
report_compressor_all_win:    # Path and name of .zip file with utility for compressing HTML report before
report_compressor_all_win:    # storing it in the database defined by <results_storage_fbk> parameter.
report_compressor_all_win:    #
report_compressor_all_win:    # Apropriate .zip file must present in {OLTP_ROOT}\util\compressors\ directory.
report_compressor_all_win:    # Path must be specified RELATIVELY current folder. Do not change it if uncomment.
report_compressor_all_win:    # Currently two compressors are provided in this test package: 7-Zip and Z-Standard.
report_compressor_all_win:    #
report_compressor_all_win:    # You don't need to extract these binaries because script will do it every time
report_compressor_all_win:    # at the end of test, before its finish.
report_compressor_all_win:    # Extraction of HTML report will be done by 'oltp_overall_report' scenario.
report_compressor_all_win:    # The utility that is used for extraction is selected based on format of compression:
report_compressor_all_win:    #     * 7z, zip or gzip ==> 7z.exe;
report_compressor_all_win:    #     * Z-Standard ==> zstd.exe.
report_compressor_all_win:    # Format that was used to compress source HTML is stored in <results_storage_fbk>,
report_compressor_all_win:    # separately for each test run.
report_compressor_all_win:    #
report_compressor_all_win:    # If this parameter remains undefined then standard ZIP format will be used.
report_compressor_all_win:    # Note that 7-Zip and zstd provide much higher compression than ZIP.
report_compressor_all_win:    # Otherwise one and only one of following lines must be uncommented:
report_compressor_all_win:    #
report_compressor_all_win:    # report_compressor=..\util\compressors\7z.exe.zip
report_compressor_all_win:    # report_compressor=..\util\compressors\zstd.exe.zip


etalon_dbnm_all:    # This parameter is used in 'oltp-scheduled' scenario and points to the name of etalone DB which serves
etalon_dbnm_all:    # as source for copy to work DB before every new test starts.
etalon_dbnm_all:    # It is possible to get following error when DB was moved from one host to another without b/r:
etalon_dbnm_all:    #     Statement failed, SQLSTATE = 22021
etalon_dbnm_all:    #     COLLATION NAME_COLL for CHARACTER SET UTF8 is not installed
etalon_dbnm_all:    # In this case try following command:
etalon_dbnm_win:    #     <fbc>\gfix.exe -icu <etalon_dbnm>
etalon_dbnm_nix:    #     <fbc>/gfix -icu <etalon_dbnm>
etalon_dbnm_all:    # NOTE.
etalon_dbnm_all:    # It is recommended to store this database in the same directory as <dbnm> and change its state to 'full shutdown'
etalon_dbnm_all:    # or at least make it read only.
etalon_dbnm_all:    #
etalon_dbnm_def_win:    etalon_dbnm = C:\data\oltp_%(fb)s.etalone.fdb
etalon_dbnm_def_nix:    etalon_dbnm = $(dirname "$dbnm")/oltp_%(fb)s.etalone.fdb


make_htm_all:    # Create report in HTML format (along with plain text) ? Avaliable options: 1 = yes, 0 = no.
make_htm_all:    # When parameter 'results_storage_fbk' is uncommented then HTML report will be saved in dedicated database and later
make_htm_all:    # will be extracted from there by {OLTP_ROOT}\util\oltp-overall-report\oltp_overall_report batch scenario.
make_htm_all:    # NOTE: time of reports creation will be increased if this parameter is set to 1.
make_htm_all:    #
make_htm_def_all:    make_html = 1


run_db_statistics_all:    # Should DB statistics be included into final report ? Avaliable options: 1 = yes, 0 = no.
run_db_statistics_all:    # When this parameter is 1, statistics output is parsed in order to get data about amount of record versions 
run_db_statistics_all:    # and maximal versions for each table. Final report will contain auxiliary table with aggregated info about versions.
run_db_statistics_all:    # WARNING. This operation can take lot of time on big databases. Replace this setting with 0 for skip this action.
run_db_statistics_all:    #
run_db_statistics_def_all:    run_db_statistics = 0


run_db_validation_all:    # Should online validation be done after test finish ? Avaliable options: 1 = yes, 0 = no.
run_db_validation_all:    # Result of validation will not include messages about passed pointer pages in order to make report shorter.
run_db_validation_all:    # WARNING. This operation can take lot of time on big databases. Replace this setting with 0 for skip this action.
run_db_validation_all:    #
run_db_validation_def_all:    run_db_validation = 0


file_name_with_test_params_all:    # This parameter defines form of final report file name which might contain info about FB and main DB/test settings.
file_name_with_test_params_all:    # Value can be one of follows:
file_name_with_test_params_all:    #     regular   - appropriate for quick found performance degradation, without details of test settings
file_name_with_test_params_all:    #     benchmark - appropriate for analysis when different settings are applied
file_name_with_test_params_all:    #
file_name_with_test_params_all:    # Report file name always consists of tokens that reflect:
file_name_with_test_params_all:    #     * Performance score;
file_name_with_test_params_all:    #     * FB snapshot number;
file_name_with_test_params_all:    #     * ServerMode value;
file_name_with_test_params_all:    #     * Test phase duration (hours and minutes);
file_name_with_test_params_all:    #     * Number of worked sessions;
file_name_with_test_params_all:    #     * Forced Writes value;
file_name_with_test_params_all:    #     * Number of CPU cores;
file_name_with_test_params_all:    #     * Total RAM size, Gb;
file_name_with_test_params_all:    #     * Timestamp when test started.
file_name_with_test_params_all:    # Example of report name when this parameter is 'regular':
file_name_with_test_params_25x_all:    #     YYYYmmDD_HHMM_score_00957_build_27152_sc%(fb)s__3h00m_100_att_fw__on_cpu4_ram32.txt
file_name_with_test_params_30x_all:    #     YYYYmmDD_HHMM_score_06543_build_31236_ss%(fb)s__3h00m_100_att_fw__on_cpu4_ram32.txt
file_name_with_test_params_40x_all:    #     YYYYmmDD_HHMM_score_07011_build_2241_ss%(fb)s__3h00m_100_att_fw__on_cpu4_ram32.txt
file_name_with_test_params_50x_all:    #     YYYYmmDD_HHMM_score_07182_build__192_ss%(fb)s__3h00m_100_att_fw__on_cpu4_ram32.txt
file_name_with_test_params_all:    # Example of report name when this parameter is 'benchmark':
file_name_with_test_params_25x_all:    #     sc%(fb)s_fw_off_split_most__sel_1st_one_index_score_02545_build_27152__3h00m_100_att_YYYYmmDD_HHMM_cpu4_ram32.txt
file_name_with_test_params_30x_all:    #     ss%(fb)s_fw_off_split_most__sel_1st_one_index_score_06915_build_31236__3h00m_100_att_YYYYmmDD_HHMM_cpu4_ram32.txt
file_name_with_test_params_40x_all:    #     ss%(fb)s_fw_off_split_most__sel_1st_one_index_score_07989_build_2241__3h00m_100_att_YYYYmmDD_HHMM_cpu4_ram32.txt
file_name_with_test_params_50x_all:    #     ss%(fb)s_fw_off_split_most__sel_1st_one_index_score_07182_build__192__3h00m_100_att_YYYYmmDD_HHMM_cpu4_ram32.txt
file_name_with_test_params_all:    #     (where 'YYYYmmDD_HHMM' is timestamp of test start)
file_name_with_test_params_all:    #
file_name_with_test_params_all:    # Available options when uncommented: regular | benchmark
file_name_with_test_params_all:    #
file_name_with_test_params_def_all:    file_name_with_test_params = regular


file_name_this_host_info_all:    # Suffix for adding at the end of report name. CHANGE this value to some useful info about host location, 
file_name_this_host_info_all:    # operating system, hardware specifics, FB instance etc.
file_name_this_host_info_win:    # For example, use value of %%COMPUTERNAME%% environment variable
file_name_this_host_info_nix:    # For example, use value of 'hostname' command.
file_name_this_host_info_all:    # You do not need to specify here number of CPU cores or RAM size: they will be added to file name by test itself.
file_name_this_host_info_all:    #
file_name_this_host_info_def_win:    file_name_this_host_info = !COMPUTERNAME!
file_name_this_host_info_def_nix:    file_name_this_host_info = linux_hostname


gather_hardware_info_all:    # Do we want to include in the report details about server hardware and OS ?
gather_hardware_info_all:    # Avaliable options: 1 = yes, 0 = no.
gather_hardware_info_all:    # This setting has sense only when you launch ISQL sessions at the server which you are 
gather_hardware_info_all:    # interesting on, i.e. when value of 'host' parameter is localhost or 127.0.0.1
gather_hardware_info_all:    # Some kind of information can be inaccessible if you work as user without admin rights.
gather_hardware_info_nix:    # NOTE: scenario that is launched by cron will see PATH=/usr/bin:/bin, i.e. some utilities from /usr/sbin
gather_hardware_info_nix:    # will not be avaliable. Some of these utilities ((e.g. fdisk and dmidecode) are used to gather hardware data.
gather_hardware_info_nix:    # This can be solved if cron job line will contain: " . /etc/profile; " before the command that is to be launched.
gather_hardware_info_nix:    # Example:
gather_hardware_info_nix:    # 0   10,20     *       *       *     . /etc/profile; /opt/oltp-emul/1run_oltp_emul.sh 30 100
gather_hardware_info_nix:    #
gather_hardware_info_nix:    # See also: https://unix.stackexchange.com/questions/148133/how-to-set-crontab-path-variable
gather_hardware_info_all:    #
gather_hardware_info_def_all:    gather_hardware_info = 1


intro08_all: #::::::::::::::::::::::::::::::::::::::::::::::::::::
intro08_all: #  EXOTIC SETTINGS (USAGE HAS NOT BEEN DEEPLY TESTED)
intro08_all: #::::::::::::::::::::::::::::::::::::::::::::::::::::

is_embed_all:    # Does Firebird running in embedded mode ? (1=yes, 0=no)
is_embed_all:    #
is_embed_def_all:    is_embed = 0

